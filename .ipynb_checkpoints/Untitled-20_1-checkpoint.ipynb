{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66eb0c51-9137-4f97-b79d-1cb0225db889",
   "metadata": {},
   "source": [
    "# Final Capstone Project (Module 20.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb1345a-42dc-4b1b-b619-0dacdcb16e61",
   "metadata": {},
   "source": [
    "**Autor (Estudiante):** José Luis Álvarez González"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3beffb-c67f-459b-93a3-27cacd361051",
   "metadata": {},
   "source": [
    "# Theme: Support tickets classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc9ceba-c65e-4e7d-9f88-fb43ea902d80",
   "metadata": {},
   "source": [
    "![Gráfico de datos](images/help-desk.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16c8a75-825f-44d5-a282-5b0feb397439",
   "metadata": {},
   "source": [
    "### Abstract:\n",
    "    - El objetivo principal es crear un sistema de clasificación automática para predecir la prioridad de tickets de soporte técnico informático \n",
    "    - Los niveles de prioridad a predecir son: \n",
    "        - Prioritario \n",
    "        - Medio \n",
    "        - Bajo \n",
    "        - Primary \n",
    "         Social \n",
    "    - Las variables clave para la predicción son: \n",
    "        • Remitente del ticket \n",
    "        • Contexto del ticket (contenido textual) \n",
    "        • Tiempo sin atender \n",
    "        • Imágenes adjuntas \n",
    "    - El sistema debe proponer una priorización independiente de la asignada inicialmente por el remitente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdfbb1f-e731-4f27-a27a-f918ac727947",
   "metadata": {},
   "source": [
    "# 1. Comprensión del Negocio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfff3d25-1f3a-469a-b616-55e115e4789f",
   "metadata": {},
   "source": [
    "### 1.1 Determinación de los Objetivos de Negocio\n",
    "\n",
    "### Contexto del Negocio\n",
    "- Se trata de un sistema de soporte técnico informático que maneja tickets\n",
    "- Actualmente la priorización inicial es asignada por el remitente\n",
    "- Se necesita un sistema que pueda sugerir una priorización más objetiva\n",
    "\n",
    "### Objetivo Principal del Negocio\n",
    "Desarrollar un sistema automatizado que prediga y sugiera la prioridad correcta de los tickets de soporte técnico, mejorando la eficiencia en la atención y resolución de incidentes.\n",
    "\n",
    "### Objetivos Específicos\n",
    "1. Crear un modelo predictivo que clasifique tickets en diferentes niveles de prioridad\n",
    "2. Reducir la subjetividad en la asignación de prioridades\n",
    "3. Optimizar la gestión del tiempo de respuesta según la prioridad real\n",
    "4. Mejorar la distribución de recursos de soporte técnico\n",
    "\n",
    "## 1.2 Evaluación de la Situación\n",
    "\n",
    "### Recursos Disponibles\n",
    "- Dataset de tickets históricos con las siguientes columnas:\n",
    "  - title: Título del ticket\n",
    "  - body: Contenido del ticket\n",
    "  - ticket_type: Tipo de ticket\n",
    "  - category: Categoría actual (valores del 1-12)\n",
    "  - sub_category1 y sub_category2: Subcategorías\n",
    "  - business_service: Servicio de negocio\n",
    "  - urgency: Nivel de urgencia\n",
    "  - impact: Nivel de impacto\n",
    "\n",
    "### Requisitos del Proyecto\n",
    "1. Procesamiento de datos textuales (título y cuerpo del ticket)\n",
    "2. Capacidad de manejar múltiples categorías\n",
    "3. Sistema de evaluación de precisión en la clasificación\n",
    "4. Interfaz para clasificar nuevos tickets (en le cuarderno jupyter)\n",
    "\n",
    "### Desafíos y Limitaciones\n",
    "1. Mapeo necesario entre categorías actuales y niveles de prioridad deseados\n",
    "2. No se observan datos explícitos sobre:\n",
    "   - Tiempo sin atender los tickets\n",
    "   - Información del remitente\n",
    "   - Imágenes adjuntas\n",
    "3. Posible desbalance en las categorías (observado en los datos)\n",
    "\n",
    "## 1.3 Determinación de Objetivos de Data Mining\n",
    "\n",
    "### Objetivos Técnicos\n",
    "1. Desarrollar un modelo de clasificación multiclase que:\n",
    "   - Procese texto en lenguaje natural\n",
    "   - Maneje características numéricas y categóricas\n",
    "   - Proporcione probabilidades de clasificación\n",
    "2. Implementar preprocesamiento de texto que:\n",
    "   - Limpie y normalice el texto\n",
    "   - Extraiga características relevantes\n",
    "   - Maneje diferentes idiomas si es necesario\n",
    "3. Crear un sistema de evaluación que mida:\n",
    "   - Precisión general del modelo\n",
    "   - Rendimiento por categoría\n",
    "   - Confiabilidad de las predicciones\n",
    "\n",
    "### Criterios de Éxito\n",
    "\n",
    "1. Técnicos:\n",
    "   - Precisión global > 80%\n",
    "   - F1-score balanceado entre categorías\n",
    "   - Tiempo de respuesta rápido para nuevos tickets\n",
    "\n",
    "2. De Negocio:\n",
    "   - Reducción en tiempo de respuesta para tickets críticos\n",
    "   - Mejor distribución de carga de trabajo\n",
    "   - Mayor satisfacción del usuario final\n",
    "\n",
    "## 1.4 Plan del Proyecto\n",
    "Nota: Este es el plan ideal para fines academicos algunos pasos son implicitos.\n",
    "### Fases Siguientes\n",
    "1. Comprensión de los Datos:\n",
    "   - Análisis detallado de la distribución de categorías\n",
    "   - Exploración de relaciones entre variables\n",
    "   - Identificación de patrones en el texto\n",
    "\n",
    "2. Preparación de los Datos:\n",
    "   - Limpieza y normalización de texto\n",
    "   - Tratamiento de valores faltantes\n",
    "   - Codificación de variables categóricas\n",
    "   - Balanceo de clases si es necesario\n",
    "\n",
    "3. Modelado:\n",
    "   - Selección de algoritmos apropiados\n",
    "   - Entrenamiento y validación\n",
    "   - Ajuste de hiperparámetros\n",
    "\n",
    "4. Evaluación:\n",
    "   - Validación cruzada\n",
    "   - Análisis de errores\n",
    "   - Evaluación de métricas por categoría\n",
    "5. Implementación:\n",
    "   - Sistema de clasificación en tiempo real\n",
    "   - Documentación del modelo (comentarios en codigo)\n",
    "   - Guías de uso y mantenimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae78e0c-46c2-40f3-9088-95996c718817",
   "metadata": {},
   "source": [
    "# 2. Comprensión de los Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7244f8ed-188b-48c4-95c5-b49043d8b45d",
   "metadata": {},
   "source": [
    "### 2.0 Librerias y bibliotecas Python para el proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "757af5c5-abbd-473a-aa6e-c6edacf2455c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "\n",
    "# 2. Preprocesamiento del texto\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee32effb-3368-4a0d-bf91-64317f220714",
   "metadata": {},
   "source": [
    "### 2.1 Recolección de Datos Iniciales "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "986fc204-42a4-47c4-8c1a-65da88712d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>ticket_type</th>\n",
       "      <th>category</th>\n",
       "      <th>sub_category1</th>\n",
       "      <th>sub_category2</th>\n",
       "      <th>business_service</th>\n",
       "      <th>urgency</th>\n",
       "      <th>impact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>hi since recruiter lead permission approve req...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>71</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>connection with icon</td>\n",
       "      <td>icon dear please setup icon per icon engineers...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>work experience user</td>\n",
       "      <td>work experience user hi work experience studen...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>requesting for meeting</td>\n",
       "      <td>requesting meeting hi please help follow equip...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>reset passwords for external accounts</td>\n",
       "      <td>re expire days hi ask help update passwords co...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>76</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   title  \\\n",
       "0                                    NaN   \n",
       "1                   connection with icon   \n",
       "2                   work experience user   \n",
       "3                 requesting for meeting   \n",
       "4  reset passwords for external accounts   \n",
       "\n",
       "                                                body  ticket_type  category  \\\n",
       "0  hi since recruiter lead permission approve req...            1         4   \n",
       "1  icon dear please setup icon per icon engineers...            1         6   \n",
       "2  work experience user hi work experience studen...            1         5   \n",
       "3  requesting meeting hi please help follow equip...            1         5   \n",
       "4  re expire days hi ask help update passwords co...            1         4   \n",
       "\n",
       "   sub_category1  sub_category2  business_service  urgency  impact  \n",
       "0              2             21                71        3       4  \n",
       "1             22              7                26        3       4  \n",
       "2             13              7                32        3       4  \n",
       "3             13              7                32        3       4  \n",
       "4              2             76                 4        3       4  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Cargar el archivo CSV proporcionado por el usuario\n",
    "file_path = \"all_tickets.csv\"\n",
    "\n",
    "# Leer el archivo para exploración inicial\n",
    "tickets_data = pd.read_csv(file_path)\n",
    "\n",
    "# Mostrar las primeras filas del dataset para revisar su estructura\n",
    "tickets_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eef04ad-deca-4a64-9134-5182f798a3bc",
   "metadata": {},
   "source": [
    "### 2.2 Descripción de los Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a03df91-d78f-43ab-b306-ef45c9050fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title               712\n",
      "body                  0\n",
      "ticket_type           0\n",
      "category              0\n",
      "sub_category1         0\n",
      "sub_category2         0\n",
      "business_service      0\n",
      "urgency               0\n",
      "impact                0\n",
      "dtype: int64\n",
      "Valores nulos en 'text': 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Verifica los valores nulos\n",
    "print(tickets_data.isnull().sum())\n",
    "\n",
    "# Combina 'title' y 'body' en una nueva columna 'text'\n",
    "tickets_data['text'] = tickets_data['title'].fillna('') + \" \" + tickets_data['body'].fillna('')\n",
    "\n",
    "# Verifica que 'text' no tenga valores nulos\n",
    "print(f\"Valores nulos en 'text': {tickets_data['text'].isnull().sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2580010-c1bf-4840-9a43-8a181855c265",
   "metadata": {},
   "source": [
    "### 2.3 Exploración de los Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9485af6e-8536-44a1-a089-03e0a05af2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n",
      "4     34061\n",
      "5      9634\n",
      "6      2628\n",
      "7       921\n",
      "11      612\n",
      "8       239\n",
      "9       191\n",
      "3       137\n",
      "1        72\n",
      "12       45\n",
      "0         4\n",
      "2         3\n",
      "10        2\n",
      "Name: count, dtype: int64\n",
      "count    48549.000000\n",
      "mean       290.619271\n",
      "std        387.195369\n",
      "min          6.000000\n",
      "25%        109.000000\n",
      "50%        174.000000\n",
      "75%        303.000000\n",
      "max       7015.000000\n",
      "Name: text_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Distribución de categorías\n",
    "print(tickets_data['category'].value_counts())\n",
    "\n",
    "# Longitudes del texto\n",
    "tickets_data['text_length'] = tickets_data['text'].apply(len)\n",
    "print(tickets_data['text_length'].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4f0b38-28f8-4afb-ab5e-0438a7149029",
   "metadata": {},
   "source": [
    "### 2.4 Hallazgos Clave\n",
    "\n",
    "1. **Estructura del Dataset:**\n",
    "   - 9 columnas: title, body, ticket_type, category, sub_category1, sub_category2, business_service, urgency, impact\n",
    "   - Cada ticket tiene un título y un cuerpo de texto\n",
    "\n",
    "2. **Valores Nulos:**\n",
    "   - Solo hay valores nulos en la columna 'title' (712 registros)\n",
    "   - El resto de columnas están completas\n",
    "   - Se creó una columna 'text' combinando title y body sin valores nulos\n",
    "\n",
    "3. **Distribución de Categorías:**\n",
    "   - Alta desbalance en las categorías\n",
    "   - Categoría 4 domina con 34,061 registros (70.16%)\n",
    "   - Categoría 5 segunda más común con 9,634 registros (19.84%)\n",
    "   - Categorías 0, 2, y 10 tienen muy pocos registros (< 5)\n",
    "\n",
    "4. **Análisis de Texto:**\n",
    "   - Longitud media de texto: 290.62 caracteres\n",
    "   - Longitud mínima: 6 caracteres\n",
    "   - Longitud máxima: 7,015 caracteres\n",
    "   - 50% de los tickets tienen entre 109 y 303 caracteres\n",
    "\n",
    "## 2.5 Implicaciones para el Modelado\n",
    "\n",
    "1. **Tratamiento de Desbalance:**\n",
    "   - Será necesario aplicar técnicas de balanceo debido a la gran diferencia entre categorías\n",
    "   - Considerar combinar o eliminar categorías con muy pocos ejemplos (0, 2, 10)\n",
    "\n",
    "2. **Procesamiento de Texto:**\n",
    "   - Los textos varían significativamente en longitud\n",
    "   - Se deberá normalizar y tokenizar el texto\n",
    "   - La columna 'text' combinada será la base para el análisis textual\n",
    "\n",
    "3. **Valores Nulos:**\n",
    "   - No será necesario un tratamiento especial de valores nulos para el modelo final\n",
    "   - La estrategia de combinar title y body fue efectiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd599037-46a9-4983-a0e1-3d9c0a056db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Importación de bibliotecas necesarias\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "383b9c3a-bfe6-476d-bf40-abd6f6879e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ****************************************************************************************\n",
    "# Visualización de datos (para agregar después de la carga de datos)\n",
    "# ****************************************************************************************\n",
    "\n",
    "# Visualización de variables categóricas (frecuencia de clases)\n",
    "# Se recomienda insertar esto después de cargar el DataFrame con los datos y antes de la división entre entrenamiento y prueba\n",
    "def plot_categorical_data(tickets_data, column):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.countplot(x=column, data=tickets_data)\n",
    "    plt.title(f\"Frecuencia de categorías en {column}\")\n",
    "    plt.show()\n",
    "\n",
    "# Visualización de variables continuas (distribución de características numéricas)\n",
    "# Se recomienda insertar esto después de la carga de datos y la limpieza inicial\n",
    "def plot_continuous_data(tickets_data, column):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.histplot(tickets_data[column], kde=True)\n",
    "    plt.title(f\"Distribución de {column}\")\n",
    "    plt.show()\n",
    "\n",
    "# Ejemplo de visualización de correlación entre variables numéricas\n",
    "def plot_correlation_matrix(tickets_data):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    corr_matrix = tickets_data.corr()\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "    plt.title(\"Matriz de Correlación\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb21f55-9cf3-4577-af79-87a50be79f6c",
   "metadata": {},
   "source": [
    "# 3. Preparación de los Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a4e6a4-53f5-41a0-8e56-0cbad6d31d07",
   "metadata": {},
   "source": [
    "### 3.1 Preparación y Limpieza de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6723af68-d39f-4169-9864-9a2be855ba73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos preprocesados y balanceados listos para el modelado.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tickets_data.to_csv(\"all_tickets_cleaned.csv\", index=False)\n",
    "\n",
    "# 1. Carga de datos\n",
    "file_path = \"all_tickets_cleaned.csv\"\n",
    "tickets_data = pd.read_csv(file_path)\n",
    "\n",
    "# Combina 'title' y 'body' en una nueva columna 'text'\n",
    "tickets_data['text'] = tickets_data['title'].fillna('') + \" \" + tickets_data['body'].fillna('')\n",
    "\n",
    "\n",
    "\n",
    "# Asegúrate de descargar las stopwords y tokenizer de NLTK si no lo has hecho antes\n",
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Asegúrate de haber creado la columna 'text' a partir de 'title' y 'body'\n",
    "tickets_data['text'] = tickets_data['title'].fillna('') + \" \" + tickets_data['body'].fillna('')\n",
    "\n",
    "# Preprocesamiento del texto\n",
    "def preprocess_text(text):\n",
    "    # Eliminar caracteres especiales y números\n",
    "    text = re.sub(r\"[^a-zA-Z]\", \" \", text)\n",
    "    # Convertir a minúsculas\n",
    "    text = text.lower()\n",
    "    # Tokenizar y eliminar stopwords\n",
    "    words = word_tokenize(text)\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    return \" \".join(words)\n",
    "\n",
    "# Crear la columna 'text_clean'\n",
    "tickets_data['text_clean'] = tickets_data['text'].apply(preprocess_text)\n",
    "\n",
    "# Ahora deberías tener la columna 'text_clean' disponible para la vectorización y el modelado\n",
    "\n",
    "\n",
    "\n",
    "# 3. Balanceo de clases con SMOTE (opcional)\n",
    "X = tickets_data['text_clean']\n",
    "y = tickets_data['category']\n",
    "\n",
    "# Vectorización con TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_tfidf = vectorizer.fit_transform(X)\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# # Aplicar SMOTE al conjunto de entrenamiento\n",
    "# smote = SMOTE(random_state=42)\n",
    "# X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# Verificar el número de muestras por clase\n",
    "class_counts = Counter(y_train)\n",
    "min_class_size = min(class_counts.values())  # Tamaño de la clase más pequeña\n",
    "\n",
    "# Ajustar k_neighbors según el tamaño de la clase más pequeña\n",
    "k_neighbors = min(min_class_size - 1, 6)  # No más de 6 vecinos\n",
    "\n",
    "# Aplicar SMOTE al conjunto de entrenamiento con k_neighbors ajustado\n",
    "smote = SMOTE(random_state=42, k_neighbors=k_neighbors)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Datos preprocesados y balanceados listos para el modelado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d413e95b-7ff3-48c7-a939-87587a33ff73",
   "metadata": {},
   "source": [
    "\n",
    "**Preparación de Datos**:\n",
    "   - Texto limpio y normalizado\n",
    "   - Datos balanceados con SMOTE\n",
    "   - Vectorización TF-IDF efectiva"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210b4d52-3499-4023-8853-f24cd734bf31",
   "metadata": {},
   "source": [
    "# 4. Modelado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1a4fa3-cd6d-4301-8587-49ccf5fc8e0d",
   "metadata": {},
   "source": [
    "### 4.1 Primer Entrenamiento del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60aa0723-c29d-4664-9c4d-b428d47908cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_66091/3163976142.py:41: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Otros' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  tickets_data.loc[tickets_data['category'].isin(classes_to_reassign), 'category'] = 'Otros'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cargar los datos preprocesados\n",
    "file_path = \"all_tickets_cleaned.csv\"\n",
    "tickets_data = pd.read_csv(file_path)\n",
    "\n",
    "# Combina 'title' y 'body' en una nueva columna 'text'\n",
    "tickets_data['text'] = tickets_data['title'].fillna('') + \" \" + tickets_data['body'].fillna('')\n",
    "\n",
    "# Asegúrate de que 'text_clean' se generó correctamente si no existía\n",
    "if 'text_clean' not in tickets_data.columns:\n",
    "    # Preprocesamiento del texto\n",
    "    import re\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.tokenize import word_tokenize\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    def preprocess_text(text):\n",
    "        # Eliminar caracteres especiales y números\n",
    "        text = re.sub(r\"[^a-zA-Z]\", \" \", text)\n",
    "        # Convertir a minúsculas\n",
    "        text = text.lower()\n",
    "        # Tokenizar y eliminar stopwords\n",
    "        words = word_tokenize(text)\n",
    "        words = [word for word in words if word not in stop_words]\n",
    "        return \" \".join(words)\n",
    "\n",
    "    tickets_data['text_clean'] = tickets_data['text'].apply(preprocess_text)\n",
    "\n",
    "# Dividir en variables de características (X) y etiquetas (y)\n",
    "X = tickets_data['text_clean']\n",
    "y = tickets_data['category']\n",
    "\n",
    "# Vectorización con TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_tfidf = vectorizer.fit_transform(X)\n",
    "\n",
    "\n",
    "# Reasignar las clases con menos de 5 ejemplos a \"Otros\"\n",
    "classes_to_reassign = y.value_counts()[y.value_counts() < 5].index\n",
    "tickets_data.loc[tickets_data['category'].isin(classes_to_reassign), 'category'] = 'Otros'\n",
    "\n",
    "# Volver a definir X e y después de reasignar\n",
    "X = tickets_data['text_clean']\n",
    "y = tickets_data['category']\n",
    "\n",
    "# Volver a hacer la división de los datos\n",
    "X_tfidf = vectorizer.fit_transform(X)\n",
    "\n",
    "\n",
    "# Convertir todas las etiquetas a cadenas de texto\n",
    "y = y.astype(str)\n",
    "\n",
    "# Luego puedes continuar con el resto del código sin problemas\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_tfidf, y, test_size=0.3, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "\n",
    "# Balanceo de clases con SMOTE en el conjunto de entrenamiento\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Crear y entrenar el modelo Naive Bayes\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Realizar predicciones en el conjunto de validación\n",
    "y_val_pred = model.predict(X_val)\n",
    "\n",
    "# Evaluar el modelo usando métricas: precisión, recall, F1-score\n",
    "print(\"Métricas en el conjunto de validación:\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "# Mostrar la matriz de confusión\n",
    "print(\"Matriz de Confusión (Validación):\")\n",
    "print(confusion_matrix(y_val, y_val_pred))\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "y_test_pred = model.predict(X_test)\n",
    "print(\"Métricas en el conjunto de prueba:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(\"Matriz de Confusión (Prueba):\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "\n",
    "# Validación Cruzada (Cross-validation) para evaluar la estabilidad\n",
    "cross_val_scores = cross_val_score(model, X_tfidf, y, cv=5, scoring='accuracy')\n",
    "print(\"Validación Cruzada (precisión promedio):\", np.mean(cross_val_scores))\n",
    "\n",
    "# Evaluar la estabilidad del modelo mediante precisión sobre varias particiones\n",
    "print(f\"Precisión media de validación cruzada: {np.mean(cross_val_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b26a58-01ca-4ec6-8386-8330ababf841",
   "metadata": {},
   "source": [
    "#### **Nota:** \n",
    "\n",
    "**Es normal encontrar advertencias durante este proceso, la advertencia relacionada con el tipo de datos incompatible, en el siguiente ajuste se asegurará en convertir la columna category al tipo str antes de realizar la asignación.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db205c69-ffcc-4f85-a952-8517c86db81c",
   "metadata": {},
   "source": [
    "### 4.2 Análisis de Distribución de Categorías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a34dbcd-ce76-4f7e-b515-186ddaf75ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d973d1a8-9a6e-46e1-8af7-5f5407b3209f",
   "metadata": {},
   "source": [
    "### 4.3 Refinamiento del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa169da0-87a0-43c3-84eb-2534924f2aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cargar los datos preprocesados\n",
    "file_path = \"all_tickets_cleaned.csv\"\n",
    "tickets_data = pd.read_csv(file_path)\n",
    "\n",
    "# Combinar 'title' y 'body' en una nueva columna 'text'\n",
    "tickets_data['text'] = tickets_data['title'].fillna('') + \" \" + tickets_data['body'].fillna('')\n",
    "\n",
    "# Asegúrate de que 'text_clean' se generó correctamente si no existía\n",
    "if 'text_clean' not in tickets_data.columns:\n",
    "    # Preprocesamiento del texto\n",
    "    import re\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.tokenize import word_tokenize\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    def preprocess_text(text):\n",
    "        # Eliminar caracteres especiales y números\n",
    "        text = re.sub(r\"[^a-zA-Z]\", \" \", text)\n",
    "        # Convertir a minúsculas\n",
    "        text = text.lower()\n",
    "        # Tokenizar y eliminar stopwords\n",
    "        words = word_tokenize(text)\n",
    "        words = [word for word in words if word not in stop_words]\n",
    "        return \" \".join(words)\n",
    "\n",
    "    tickets_data['text_clean'] = tickets_data['text'].apply(preprocess_text)\n",
    "\n",
    "# Convertir la columna 'category' a tipo str\n",
    "tickets_data['category'] = tickets_data['category'].astype(str)\n",
    "\n",
    "# Reasignar las clases con menos de 5 ejemplos a 'Otros'\n",
    "classes_to_reassign = tickets_data['category'].value_counts()[tickets_data['category'].value_counts() < 5].index\n",
    "tickets_data.loc[tickets_data['category'].isin(classes_to_reassign), 'category'] = 'Otros'\n",
    "\n",
    "# Actualizar X e y después del cambio\n",
    "X = tickets_data['text_clean']\n",
    "y = tickets_data['category']\n",
    "\n",
    "# Vectorización con TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_tfidf = vectorizer.fit_transform(X)\n",
    "\n",
    "# División de los datos\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_tfidf, y, test_size=0.3, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "# Balanceo de clases con SMOTE en el conjunto de entrenamiento\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Crear y entrenar el modelo Naive Bayes\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Realizar predicciones en el conjunto de validación\n",
    "y_val_pred = model.predict(X_val)\n",
    "\n",
    "# Evaluar el modelo usando métricas: precisión, recall, F1-score\n",
    "print(\"Métricas en el conjunto de validación:\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "# Mostrar la matriz de confusión\n",
    "print(\"Matriz de Confusión (Validación):\")\n",
    "print(confusion_matrix(y_val, y_val_pred))\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "y_test_pred = model.predict(X_test)\n",
    "print(\"Métricas en el conjunto de prueba:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(\"Matriz de Confusión (Prueba):\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "\n",
    "# Validación Cruzada (Cross-validation) para evaluar la estabilidad\n",
    "cross_val_scores = cross_val_score(model, X_tfidf, y, cv=5, scoring='accuracy')\n",
    "print(\"Validación Cruzada (precisión promedio):\", np.mean(cross_val_scores))\n",
    "\n",
    "# Evaluar la estabilidad del modelo mediante precisión sobre varias particiones\n",
    "print(f\"Precisión media de validación cruzada: {np.mean(cross_val_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdfa8f4-2f05-4efa-a094-204a6f5517d3",
   "metadata": {},
   "source": [
    "\n",
    "**Modelado**:\n",
    "   - Modelo Naive Bayes implementado\n",
    "   - Precisión global de 83.07%\n",
    "   - Mejor rendimiento en categorías mayoritarias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f737b2d5-c3dc-4b55-bc76-191c5ef72670",
   "metadata": {},
   "source": [
    "#### Resultados principales de la evaluación\n",
    "\n",
    "Accuracy promedio: 0.8307 (83.07%)\n",
    "Mejor desempeño en categorías mayoritarias (4 y 5)\n",
    "Desempeño más bajo en categorías minoritarias, lo cual es de esperarse en base a dataset que se tiene."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d27632-8d52-4e1f-8296-57e1955913c2",
   "metadata": {},
   "source": [
    "# 5. Evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54e5559-979e-4e0c-9e08-d9e61012dae6",
   "metadata": {},
   "source": [
    "### 5.1 Evaluación del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dccebc-0845-49e0-bd1a-b375d5edaed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('model' in locals())\n",
    "print('vectorizer' in locals())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5365ca3-6a92-4586-a8ee-66ce3253f620",
   "metadata": {},
   "source": [
    "El modelo (model) y el vectorizador (vectorizer) estén cargados correctamente en el entorno de ejecución.\n",
    "Resultado: La evaluación muestra que ambos objetos están presentes y correctamente cargados en memoria (True para ambos), lo que indica que están listos para usarse en la clasificación de nuevos tickets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f84285a-3a3c-406b-9348-7358ddebf2e2",
   "metadata": {},
   "source": [
    "Muchas Gracias!!! :D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adba9271-b3b6-4213-9305-d5778fee94b4",
   "metadata": {},
   "source": [
    "**End!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701d5297-4103-497b-bde3-63a579cb2f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
