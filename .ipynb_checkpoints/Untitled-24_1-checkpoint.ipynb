{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66eb0c51-9137-4f97-b79d-1cb0225db889",
   "metadata": {},
   "source": [
    "# Final Capstone Project (Module 24.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb1345a-42dc-4b1b-b619-0dacdcb16e61",
   "metadata": {},
   "source": [
    "**Autor (Estudiante):** José Luis Álvarez González"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3beffb-c67f-459b-93a3-27cacd361051",
   "metadata": {},
   "source": [
    "# Theme: Support tickets classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc9ceba-c65e-4e7d-9f88-fb43ea902d80",
   "metadata": {},
   "source": [
    "![Gráfico de datos](images/help-desk.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16c8a75-825f-44d5-a282-5b0feb397439",
   "metadata": {},
   "source": [
    "### Abstract:\n",
    "    - El objetivo principal es crear un sistema de clasificación automática para predecir la prioridad de tickets de soporte técnico informático \n",
    "    - Los niveles de prioridad a predecir son: \n",
    "        - Prioritario \n",
    "        - Medio \n",
    "        - Bajo \n",
    "        - Primary \n",
    "         Social \n",
    "    - Las variables clave para la predicción son: \n",
    "        • Remitente del ticket \n",
    "        • Contexto del ticket (contenido textual) \n",
    "        • Tiempo sin atender \n",
    "        • Imágenes adjuntas \n",
    "    - El sistema debe proponer una priorización independiente de la asignada inicialmente por el remitente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdfbb1f-e731-4f27-a27a-f918ac727947",
   "metadata": {},
   "source": [
    "# 1. Comprensión del Negocio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfff3d25-1f3a-469a-b616-55e115e4789f",
   "metadata": {},
   "source": [
    "### 1.1 Determinación de los Objetivos de Negocio\n",
    "\n",
    "### Contexto del Negocio\n",
    "- Se trata de un sistema de soporte técnico informático que maneja tickets\n",
    "- Actualmente la priorización inicial es asignada por el remitente\n",
    "- Se necesita un sistema que pueda sugerir una priorización más objetiva\n",
    "\n",
    "### Objetivo Principal del Negocio\n",
    "Desarrollar un sistema automatizado que prediga y sugiera la prioridad correcta de los tickets de soporte técnico, mejorando la eficiencia en la atención y resolución de incidentes.\n",
    "\n",
    "### Objetivos Específicos\n",
    "1. Crear un modelo predictivo que clasifique tickets en diferentes niveles de prioridad\n",
    "2. Reducir la subjetividad en la asignación de prioridades\n",
    "3. Optimizar la gestión del tiempo de respuesta según la prioridad real\n",
    "4. Mejorar la distribución de recursos de soporte técnico\n",
    "\n",
    "## 1.2 Evaluación de la Situación\n",
    "\n",
    "### Recursos Disponibles\n",
    "- Dataset de tickets históricos con las siguientes columnas:\n",
    "  - title: Título del ticket\n",
    "  - body: Contenido del ticket\n",
    "  - ticket_type: Tipo de ticket\n",
    "  - category: Categoría actual (valores del 1-12)\n",
    "  - sub_category1 y sub_category2: Subcategorías\n",
    "  - business_service: Servicio de negocio\n",
    "  - urgency: Nivel de urgencia\n",
    "  - impact: Nivel de impacto\n",
    "\n",
    "### Requisitos del Proyecto\n",
    "1. Procesamiento de datos textuales (título y cuerpo del ticket)\n",
    "2. Capacidad de manejar múltiples categorías\n",
    "3. Sistema de evaluación de precisión en la clasificación\n",
    "4. Interfaz para clasificar nuevos tickets (en le cuarderno jupyter)\n",
    "\n",
    "### Desafíos y Limitaciones\n",
    "1. Mapeo necesario entre categorías actuales y niveles de prioridad deseados\n",
    "2. No se observan datos explícitos sobre:\n",
    "   - Tiempo sin atender los tickets\n",
    "   - Información del remitente\n",
    "   - Imágenes adjuntas\n",
    "3. Posible desbalance en las categorías (observado en los datos)\n",
    "\n",
    "## 1.3 Determinación de Objetivos de Data Mining\n",
    "\n",
    "### Objetivos Técnicos\n",
    "1. Desarrollar un modelo de clasificación multiclase que:\n",
    "   - Procese texto en lenguaje natural\n",
    "   - Maneje características numéricas y categóricas\n",
    "   - Proporcione probabilidades de clasificación\n",
    "2. Implementar preprocesamiento de texto que:\n",
    "   - Limpie y normalice el texto\n",
    "   - Extraiga características relevantes\n",
    "   - Maneje diferentes idiomas si es necesario\n",
    "3. Crear un sistema de evaluación que mida:\n",
    "   - Precisión general del modelo\n",
    "   - Rendimiento por categoría\n",
    "   - Confiabilidad de las predicciones\n",
    "\n",
    "### Criterios de Éxito\n",
    "\n",
    "1. Técnicos:\n",
    "   - Precisión global > 80%\n",
    "   - F1-score balanceado entre categorías\n",
    "   - Tiempo de respuesta rápido para nuevos tickets\n",
    "\n",
    "2. De Negocio:\n",
    "   - Reducción en tiempo de respuesta para tickets críticos\n",
    "   - Mejor distribución de carga de trabajo\n",
    "   - Mayor satisfacción del usuario final\n",
    "\n",
    "## 1.4 Plan del Proyecto\n",
    "Nota: Este es el plan ideal para fines academicos algunos pasos son implicitos.\n",
    "### Fases Siguientes\n",
    "1. Comprensión de los Datos:\n",
    "   - Análisis detallado de la distribución de categorías\n",
    "   - Exploración de relaciones entre variables\n",
    "   - Identificación de patrones en el texto\n",
    "\n",
    "2. Preparación de los Datos:\n",
    "   - Limpieza y normalización de texto\n",
    "   - Tratamiento de valores faltantes\n",
    "   - Codificación de variables categóricas\n",
    "   - Balanceo de clases si es necesario\n",
    "\n",
    "3. Modelado:\n",
    "   - Selección de algoritmos apropiados\n",
    "   - Entrenamiento y validación\n",
    "   - Ajuste de hiperparámetros\n",
    "\n",
    "4. Evaluación:\n",
    "   - Validación cruzada\n",
    "   - Análisis de errores\n",
    "   - Evaluación de métricas por categoría\n",
    "5. Implementación:\n",
    "   - Sistema de clasificación en tiempo real\n",
    "   - Documentación del modelo (comentarios en codigo)\n",
    "   - Guías de uso y mantenimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae78e0c-46c2-40f3-9088-95996c718817",
   "metadata": {},
   "source": [
    "# 2. Comprensión de los Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7244f8ed-188b-48c4-95c5-b49043d8b45d",
   "metadata": {},
   "source": [
    "### 2.0 Librerias y recursos Python para el proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "757af5c5-abbd-473a-aa6e-c6edacf2455c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "\n",
    "# 2. Preprocesamiento del texto\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee32effb-3368-4a0d-bf91-64317f220714",
   "metadata": {},
   "source": [
    "### 2.1 Recolección de Datos Iniciales "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "986fc204-42a4-47c4-8c1a-65da88712d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>ticket_type</th>\n",
       "      <th>category</th>\n",
       "      <th>sub_category1</th>\n",
       "      <th>sub_category2</th>\n",
       "      <th>business_service</th>\n",
       "      <th>urgency</th>\n",
       "      <th>impact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>hi since recruiter lead permission approve req...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>71</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>connection with icon</td>\n",
       "      <td>icon dear please setup icon per icon engineers...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>work experience user</td>\n",
       "      <td>work experience user hi work experience studen...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>requesting for meeting</td>\n",
       "      <td>requesting meeting hi please help follow equip...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>reset passwords for external accounts</td>\n",
       "      <td>re expire days hi ask help update passwords co...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>76</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   title  \\\n",
       "0                                    NaN   \n",
       "1                   connection with icon   \n",
       "2                   work experience user   \n",
       "3                 requesting for meeting   \n",
       "4  reset passwords for external accounts   \n",
       "\n",
       "                                                body  ticket_type  category  \\\n",
       "0  hi since recruiter lead permission approve req...            1         4   \n",
       "1  icon dear please setup icon per icon engineers...            1         6   \n",
       "2  work experience user hi work experience studen...            1         5   \n",
       "3  requesting meeting hi please help follow equip...            1         5   \n",
       "4  re expire days hi ask help update passwords co...            1         4   \n",
       "\n",
       "   sub_category1  sub_category2  business_service  urgency  impact  \n",
       "0              2             21                71        3       4  \n",
       "1             22              7                26        3       4  \n",
       "2             13              7                32        3       4  \n",
       "3             13              7                32        3       4  \n",
       "4              2             76                 4        3       4  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Cargar el archivo CSV proporcionado por el usuario\n",
    "file_path = \"all_tickets.csv\"\n",
    "\n",
    "# Leer el archivo para exploración inicial\n",
    "tickets_data = pd.read_csv(file_path)\n",
    "\n",
    "# Mostrar las primeras filas del dataset para revisar su estructura\n",
    "tickets_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eef04ad-deca-4a64-9134-5182f798a3bc",
   "metadata": {},
   "source": [
    "### 2.2 Descripción de los Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a03df91-d78f-43ab-b306-ef45c9050fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title               712\n",
      "body                  0\n",
      "ticket_type           0\n",
      "category              0\n",
      "sub_category1         0\n",
      "sub_category2         0\n",
      "business_service      0\n",
      "urgency               0\n",
      "impact                0\n",
      "dtype: int64\n",
      "Valores nulos en 'text': 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Verifica los valores nulos\n",
    "print(tickets_data.isnull().sum())\n",
    "\n",
    "# Combina 'title' y 'body' en una nueva columna 'text'\n",
    "tickets_data['text'] = tickets_data['title'].fillna('') + \" \" + tickets_data['body'].fillna('')\n",
    "\n",
    "# Verifica que 'text' no tenga valores nulos\n",
    "print(f\"Valores nulos en 'text': {tickets_data['text'].isnull().sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2580010-c1bf-4840-9a43-8a181855c265",
   "metadata": {},
   "source": [
    "### 2.3 Exploración de los Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9485af6e-8536-44a1-a089-03e0a05af2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n",
      "4     34061\n",
      "5      9634\n",
      "6      2628\n",
      "7       921\n",
      "11      612\n",
      "8       239\n",
      "9       191\n",
      "3       137\n",
      "1        72\n",
      "12       45\n",
      "0         4\n",
      "2         3\n",
      "10        2\n",
      "Name: count, dtype: int64\n",
      "count    48549.000000\n",
      "mean       290.619271\n",
      "std        387.195369\n",
      "min          6.000000\n",
      "25%        109.000000\n",
      "50%        174.000000\n",
      "75%        303.000000\n",
      "max       7015.000000\n",
      "Name: text_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Distribución de categorías\n",
    "print(tickets_data['category'].value_counts())\n",
    "\n",
    "# Longitudes del texto\n",
    "tickets_data['text_length'] = tickets_data['text'].apply(len)\n",
    "print(tickets_data['text_length'].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4f0b38-28f8-4afb-ab5e-0438a7149029",
   "metadata": {},
   "source": [
    "### 2.4 Hallazgos Clave\n",
    "\n",
    "1. **Estructura del Dataset:**\n",
    "   - 9 columnas: title, body, ticket_type, category, sub_category1, sub_category2, business_service, urgency, impact\n",
    "   - Cada ticket tiene un título y un cuerpo de texto\n",
    "\n",
    "2. **Valores Nulos:**\n",
    "   - Solo hay valores nulos en la columna 'title' (712 registros)\n",
    "   - El resto de columnas están completas\n",
    "   - Se creó una columna 'text' combinando title y body sin valores nulos\n",
    "\n",
    "3. **Distribución de Categorías:**\n",
    "   - Alta desbalance en las categorías\n",
    "   - Categoría 4 domina con 34,061 registros (70.16%)\n",
    "   - Categoría 5 segunda más común con 9,634 registros (19.84%)\n",
    "   - Categorías 0, 2, y 10 tienen muy pocos registros (< 5)\n",
    "\n",
    "4. **Análisis de Texto:**\n",
    "   - Longitud media de texto: 290.62 caracteres\n",
    "   - Longitud mínima: 6 caracteres\n",
    "   - Longitud máxima: 7,015 caracteres\n",
    "   - 50% de los tickets tienen entre 109 y 303 caracteres\n",
    "\n",
    "## 2.5 Implicaciones para el Modelado\n",
    "\n",
    "1. **Tratamiento de Desbalance:**\n",
    "   - Será necesario aplicar técnicas de balanceo debido a la gran diferencia entre categorías\n",
    "   - Considerar combinar o eliminar categorías con muy pocos ejemplos (0, 2, 10)\n",
    "\n",
    "2. **Procesamiento de Texto:**\n",
    "   - Los textos varían significativamente en longitud\n",
    "   - Se deberá normalizar y tokenizar el texto\n",
    "   - La columna 'text' combinada será la base para el análisis textual\n",
    "\n",
    "3. **Valores Nulos:**\n",
    "   - No será necesario un tratamiento especial de valores nulos para el modelo final\n",
    "   - La estrategia de combinar title y body fue efectiva"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb21f55-9cf3-4577-af79-87a50be79f6c",
   "metadata": {},
   "source": [
    "# 3. Preparación de los Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a4e6a4-53f5-41a0-8e56-0cbad6d31d07",
   "metadata": {},
   "source": [
    "### 3.1 Preparación y Limpieza de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6723af68-d39f-4169-9864-9a2be855ba73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos preprocesados y balanceados listos para el modelado.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tickets_data.to_csv(\"all_tickets_cleaned.csv\", index=False)\n",
    "\n",
    "# 1. Carga de datos\n",
    "file_path = \"all_tickets_cleaned.csv\"\n",
    "tickets_data = pd.read_csv(file_path)\n",
    "\n",
    "# Combina 'title' y 'body' en una nueva columna 'text'\n",
    "tickets_data['text'] = tickets_data['title'].fillna('') + \" \" + tickets_data['body'].fillna('')\n",
    "\n",
    "\n",
    "\n",
    "# Asegúrate de descargar las stopwords y tokenizer de NLTK si no lo has hecho antes\n",
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Asegúrate de haber creado la columna 'text' a partir de 'title' y 'body'\n",
    "tickets_data['text'] = tickets_data['title'].fillna('') + \" \" + tickets_data['body'].fillna('')\n",
    "\n",
    "# Preprocesamiento del texto\n",
    "def preprocess_text(text):\n",
    "    # Eliminar caracteres especiales y números\n",
    "    text = re.sub(r\"[^a-zA-Z]\", \" \", text)\n",
    "    # Convertir a minúsculas\n",
    "    text = text.lower()\n",
    "    # Tokenizar y eliminar stopwords\n",
    "    words = word_tokenize(text)\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    return \" \".join(words)\n",
    "\n",
    "# Crear la columna 'text_clean'\n",
    "tickets_data['text_clean'] = tickets_data['text'].apply(preprocess_text)\n",
    "\n",
    "# Ahora deberías tener la columna 'text_clean' disponible para la vectorización y el modelado\n",
    "\n",
    "\n",
    "\n",
    "# 3. Balanceo de clases con SMOTE (opcional)\n",
    "X = tickets_data['text_clean']\n",
    "y = tickets_data['category']\n",
    "\n",
    "# Vectorización con TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_tfidf = vectorizer.fit_transform(X)\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# # Aplicar SMOTE al conjunto de entrenamiento\n",
    "# smote = SMOTE(random_state=42)\n",
    "# X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# Verificar el número de muestras por clase\n",
    "class_counts = Counter(y_train)\n",
    "min_class_size = min(class_counts.values())  # Tamaño de la clase más pequeña\n",
    "\n",
    "# Ajustar k_neighbors según el tamaño de la clase más pequeña\n",
    "k_neighbors = min(min_class_size - 1, 6)  # No más de 6 vecinos\n",
    "\n",
    "# Aplicar SMOTE al conjunto de entrenamiento con k_neighbors ajustado\n",
    "smote = SMOTE(random_state=42, k_neighbors=k_neighbors)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Datos preprocesados y balanceados listos para el modelado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d413e95b-7ff3-48c7-a939-87587a33ff73",
   "metadata": {},
   "source": [
    "\n",
    "**Preparación de Datos**:\n",
    "   - Texto limpio y normalizado\n",
    "   - Datos balanceados con SMOTE\n",
    "   - Vectorización TF-IDF efectiva"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210b4d52-3499-4023-8853-f24cd734bf31",
   "metadata": {},
   "source": [
    "# 4. Modelado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1a4fa3-cd6d-4301-8587-49ccf5fc8e0d",
   "metadata": {},
   "source": [
    "### 4.1 Primer Entrenamiento del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60aa0723-c29d-4664-9c4d-b428d47908cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_54663/3163976142.py:41: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Otros' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  tickets_data.loc[tickets_data['category'].isin(classes_to_reassign), 'category'] = 'Otros'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas en el conjunto de validación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.02      0.18      0.04        11\n",
      "          11       0.37      0.73      0.49        92\n",
      "          12       0.18      0.57      0.28         7\n",
      "           3       0.05      0.30      0.09        20\n",
      "           4       0.95      0.76      0.84      5109\n",
      "           5       0.81      0.69      0.75      1445\n",
      "           6       0.34      0.74      0.46       394\n",
      "           7       0.24      0.88      0.37       138\n",
      "           8       0.81      0.81      0.81        36\n",
      "           9       0.18      0.54      0.27        28\n",
      "       Otros       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.74      7282\n",
      "   macro avg       0.36      0.56      0.40      7282\n",
      "weighted avg       0.86      0.74      0.78      7282\n",
      "\n",
      "Matriz de Confusión (Validación):\n",
      "[[   2    0    0    0    8    0    1    0    0    0    0]\n",
      " [   0   67    0    0    9    3    3   10    0    0    0]\n",
      " [   0    0    4    0    2    0    1    0    0    0    0]\n",
      " [   0    0    0    6    5    7    1    0    0    0    1]\n",
      " [  79   67   15   59 3890  200  401  334    3   23   38]\n",
      " [   5   31    1   45  122  998  158   43    0   42    0]\n",
      " [   3    7    2    6   56   15  290    7    4    3    1]\n",
      " [   0   10    0    0    3    1    1  122    0    1    0]\n",
      " [   0    0    0    1    1    0    5    0   29    0    0]\n",
      " [   0    1    0    0    3    9    0    0    0   15    0]\n",
      " [   1    0    0    0    0    1    0    0    0    0    0]]\n",
      "Métricas en el conjunto de prueba:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.02      0.18      0.04        11\n",
      "          11       0.37      0.79      0.51        92\n",
      "          12       0.26      0.83      0.40         6\n",
      "           3       0.07      0.33      0.11        21\n",
      "           4       0.95      0.77      0.85      5110\n",
      "           5       0.82      0.69      0.75      1445\n",
      "           6       0.35      0.75      0.48       394\n",
      "           7       0.23      0.86      0.36       138\n",
      "           8       0.78      0.81      0.79        36\n",
      "           9       0.24      0.55      0.33        29\n",
      "       Otros       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.75      7283\n",
      "   macro avg       0.37      0.60      0.42      7283\n",
      "weighted avg       0.86      0.75      0.79      7283\n",
      "\n",
      "Matriz de Confusión (Prueba):\n",
      "[[   2    0    0    1    5    2    1    0    0    0    0]\n",
      " [   0   73    0    0    4    0    5   10    0    0    0]\n",
      " [   0    0    5    0    1    0    0    0    0    0    0]\n",
      " [   0    1    0    7    1    9    3    0    0    0    0]\n",
      " [  80   67   14   54 3950  178  391  328    6   13   29]\n",
      " [   4   36    0   41  142 1001  136   47    0   35    3]\n",
      " [   1   11    0    3   52   19  294    8    2    4    0]\n",
      " [   0    8    0    0   10    0    2  118    0    0    0]\n",
      " [   0    0    0    0    3    0    4    0   29    0    0]\n",
      " [   0    0    0    0    5    7    1    0    0   16    0]\n",
      " [   0    0    0    0    1    0    0    0    0    0    0]]\n",
      "Validación Cruzada (precisión promedio): 0.8307064368170402\n",
      "Precisión media de validación cruzada: 0.8307\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cargar los datos preprocesados\n",
    "file_path = \"all_tickets_cleaned.csv\"\n",
    "tickets_data = pd.read_csv(file_path)\n",
    "\n",
    "# Combina 'title' y 'body' en una nueva columna 'text'\n",
    "tickets_data['text'] = tickets_data['title'].fillna('') + \" \" + tickets_data['body'].fillna('')\n",
    "\n",
    "# Asegúrate de que 'text_clean' se generó correctamente si no existía\n",
    "if 'text_clean' not in tickets_data.columns:\n",
    "    # Preprocesamiento del texto\n",
    "    import re\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.tokenize import word_tokenize\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    def preprocess_text(text):\n",
    "        # Eliminar caracteres especiales y números\n",
    "        text = re.sub(r\"[^a-zA-Z]\", \" \", text)\n",
    "        # Convertir a minúsculas\n",
    "        text = text.lower()\n",
    "        # Tokenizar y eliminar stopwords\n",
    "        words = word_tokenize(text)\n",
    "        words = [word for word in words if word not in stop_words]\n",
    "        return \" \".join(words)\n",
    "\n",
    "    tickets_data['text_clean'] = tickets_data['text'].apply(preprocess_text)\n",
    "\n",
    "# Dividir en variables de características (X) y etiquetas (y)\n",
    "X = tickets_data['text_clean']\n",
    "y = tickets_data['category']\n",
    "\n",
    "# Vectorización con TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_tfidf = vectorizer.fit_transform(X)\n",
    "\n",
    "\n",
    "# Reasignar las clases con menos de 5 ejemplos a \"Otros\"\n",
    "classes_to_reassign = y.value_counts()[y.value_counts() < 5].index\n",
    "tickets_data.loc[tickets_data['category'].isin(classes_to_reassign), 'category'] = 'Otros'\n",
    "\n",
    "# Volver a definir X e y después de reasignar\n",
    "X = tickets_data['text_clean']\n",
    "y = tickets_data['category']\n",
    "\n",
    "# Volver a hacer la división de los datos\n",
    "X_tfidf = vectorizer.fit_transform(X)\n",
    "\n",
    "\n",
    "# Convertir todas las etiquetas a cadenas de texto\n",
    "y = y.astype(str)\n",
    "\n",
    "# Luego puedes continuar con el resto del código sin problemas\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_tfidf, y, test_size=0.3, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "\n",
    "# Balanceo de clases con SMOTE en el conjunto de entrenamiento\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Crear y entrenar el modelo Naive Bayes\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Realizar predicciones en el conjunto de validación\n",
    "y_val_pred = model.predict(X_val)\n",
    "\n",
    "# Evaluar el modelo usando métricas: precisión, recall, F1-score\n",
    "print(\"Métricas en el conjunto de validación:\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "# Mostrar la matriz de confusión\n",
    "print(\"Matriz de Confusión (Validación):\")\n",
    "print(confusion_matrix(y_val, y_val_pred))\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "y_test_pred = model.predict(X_test)\n",
    "print(\"Métricas en el conjunto de prueba:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(\"Matriz de Confusión (Prueba):\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "\n",
    "# Validación Cruzada (Cross-validation) para evaluar la estabilidad\n",
    "cross_val_scores = cross_val_score(model, X_tfidf, y, cv=5, scoring='accuracy')\n",
    "print(\"Validación Cruzada (precisión promedio):\", np.mean(cross_val_scores))\n",
    "\n",
    "# Evaluar la estabilidad del modelo mediante precisión sobre varias particiones\n",
    "print(f\"Precisión media de validación cruzada: {np.mean(cross_val_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b26a58-01ca-4ec6-8386-8330ababf841",
   "metadata": {},
   "source": [
    "#### **Nota:** \n",
    "\n",
    "**Es normal encontrar advertencias durante este proceso, la advertencia relacionada con el tipo de datos incompatible, en el siguiente ajuste se asegurará en convertir la columna category al tipo str antes de realizar la asignación.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db205c69-ffcc-4f85-a952-8517c86db81c",
   "metadata": {},
   "source": [
    "### 4.2 Análisis de Distribución de Categorías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a34dbcd-ce76-4f7e-b515-186ddaf75ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n",
      "4        34061\n",
      "5         9634\n",
      "6         2628\n",
      "7          921\n",
      "11         612\n",
      "8          239\n",
      "9          191\n",
      "3          137\n",
      "1           72\n",
      "12          45\n",
      "Otros        9\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d973d1a8-9a6e-46e1-8af7-5f5407b3209f",
   "metadata": {},
   "source": [
    "### 4.3 Refinamiento del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa169da0-87a0-43c3-84eb-2534924f2aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas en el conjunto de validación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.02      0.18      0.04        11\n",
      "          11       0.37      0.73      0.49        92\n",
      "          12       0.18      0.57      0.28         7\n",
      "           3       0.05      0.30      0.09        20\n",
      "           4       0.95      0.76      0.84      5109\n",
      "           5       0.81      0.69      0.75      1445\n",
      "           6       0.34      0.74      0.46       394\n",
      "           7       0.24      0.88      0.37       138\n",
      "           8       0.81      0.81      0.81        36\n",
      "           9       0.18      0.54      0.27        28\n",
      "       Otros       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.74      7282\n",
      "   macro avg       0.36      0.56      0.40      7282\n",
      "weighted avg       0.86      0.74      0.78      7282\n",
      "\n",
      "Matriz de Confusión (Validación):\n",
      "[[   2    0    0    0    8    0    1    0    0    0    0]\n",
      " [   0   67    0    0    9    3    3   10    0    0    0]\n",
      " [   0    0    4    0    2    0    1    0    0    0    0]\n",
      " [   0    0    0    6    5    7    1    0    0    0    1]\n",
      " [  79   67   15   59 3890  200  401  334    3   23   38]\n",
      " [   5   31    1   45  122  998  158   43    0   42    0]\n",
      " [   3    7    2    6   56   15  290    7    4    3    1]\n",
      " [   0   10    0    0    3    1    1  122    0    1    0]\n",
      " [   0    0    0    1    1    0    5    0   29    0    0]\n",
      " [   0    1    0    0    3    9    0    0    0   15    0]\n",
      " [   1    0    0    0    0    1    0    0    0    0    0]]\n",
      "Métricas en el conjunto de prueba:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.02      0.18      0.04        11\n",
      "          11       0.37      0.79      0.51        92\n",
      "          12       0.26      0.83      0.40         6\n",
      "           3       0.07      0.33      0.11        21\n",
      "           4       0.95      0.77      0.85      5110\n",
      "           5       0.82      0.69      0.75      1445\n",
      "           6       0.35      0.75      0.48       394\n",
      "           7       0.23      0.86      0.36       138\n",
      "           8       0.78      0.81      0.79        36\n",
      "           9       0.24      0.55      0.33        29\n",
      "       Otros       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.75      7283\n",
      "   macro avg       0.37      0.60      0.42      7283\n",
      "weighted avg       0.86      0.75      0.79      7283\n",
      "\n",
      "Matriz de Confusión (Prueba):\n",
      "[[   2    0    0    1    5    2    1    0    0    0    0]\n",
      " [   0   73    0    0    4    0    5   10    0    0    0]\n",
      " [   0    0    5    0    1    0    0    0    0    0    0]\n",
      " [   0    1    0    7    1    9    3    0    0    0    0]\n",
      " [  80   67   14   54 3950  178  391  328    6   13   29]\n",
      " [   4   36    0   41  142 1001  136   47    0   35    3]\n",
      " [   1   11    0    3   52   19  294    8    2    4    0]\n",
      " [   0    8    0    0   10    0    2  118    0    0    0]\n",
      " [   0    0    0    0    3    0    4    0   29    0    0]\n",
      " [   0    0    0    0    5    7    1    0    0   16    0]\n",
      " [   0    0    0    0    1    0    0    0    0    0    0]]\n",
      "Validación Cruzada (precisión promedio): 0.8307064368170402\n",
      "Precisión media de validación cruzada: 0.8307\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cargar los datos preprocesados\n",
    "file_path = \"all_tickets_cleaned.csv\"\n",
    "tickets_data = pd.read_csv(file_path)\n",
    "\n",
    "# Combinar 'title' y 'body' en una nueva columna 'text'\n",
    "tickets_data['text'] = tickets_data['title'].fillna('') + \" \" + tickets_data['body'].fillna('')\n",
    "\n",
    "# Asegúrate de que 'text_clean' se generó correctamente si no existía\n",
    "if 'text_clean' not in tickets_data.columns:\n",
    "    # Preprocesamiento del texto\n",
    "    import re\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.tokenize import word_tokenize\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    def preprocess_text(text):\n",
    "        # Eliminar caracteres especiales y números\n",
    "        text = re.sub(r\"[^a-zA-Z]\", \" \", text)\n",
    "        # Convertir a minúsculas\n",
    "        text = text.lower()\n",
    "        # Tokenizar y eliminar stopwords\n",
    "        words = word_tokenize(text)\n",
    "        words = [word for word in words if word not in stop_words]\n",
    "        return \" \".join(words)\n",
    "\n",
    "    tickets_data['text_clean'] = tickets_data['text'].apply(preprocess_text)\n",
    "\n",
    "# Convertir la columna 'category' a tipo str\n",
    "tickets_data['category'] = tickets_data['category'].astype(str)\n",
    "\n",
    "# Reasignar las clases con menos de 5 ejemplos a 'Otros'\n",
    "classes_to_reassign = tickets_data['category'].value_counts()[tickets_data['category'].value_counts() < 5].index\n",
    "tickets_data.loc[tickets_data['category'].isin(classes_to_reassign), 'category'] = 'Otros'\n",
    "\n",
    "# Actualizar X e y después del cambio\n",
    "X = tickets_data['text_clean']\n",
    "y = tickets_data['category']\n",
    "\n",
    "# Vectorización con TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_tfidf = vectorizer.fit_transform(X)\n",
    "\n",
    "# División de los datos\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_tfidf, y, test_size=0.3, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "# Balanceo de clases con SMOTE en el conjunto de entrenamiento\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Crear y entrenar el modelo Naive Bayes\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Realizar predicciones en el conjunto de validación\n",
    "y_val_pred = model.predict(X_val)\n",
    "\n",
    "# Evaluar el modelo usando métricas: precisión, recall, F1-score\n",
    "print(\"Métricas en el conjunto de validación:\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "# Mostrar la matriz de confusión\n",
    "print(\"Matriz de Confusión (Validación):\")\n",
    "print(confusion_matrix(y_val, y_val_pred))\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "y_test_pred = model.predict(X_test)\n",
    "print(\"Métricas en el conjunto de prueba:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(\"Matriz de Confusión (Prueba):\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "\n",
    "# Validación Cruzada (Cross-validation) para evaluar la estabilidad\n",
    "cross_val_scores = cross_val_score(model, X_tfidf, y, cv=5, scoring='accuracy')\n",
    "print(\"Validación Cruzada (precisión promedio):\", np.mean(cross_val_scores))\n",
    "\n",
    "# Evaluar la estabilidad del modelo mediante precisión sobre varias particiones\n",
    "print(f\"Precisión media de validación cruzada: {np.mean(cross_val_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdfa8f4-2f05-4efa-a094-204a6f5517d3",
   "metadata": {},
   "source": [
    "\n",
    "**Modelado**:\n",
    "   - Modelo Naive Bayes implementado\n",
    "   - Precisión global de 83.07%\n",
    "   - Mejor rendimiento en categorías mayoritarias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f737b2d5-c3dc-4b55-bc76-191c5ef72670",
   "metadata": {},
   "source": [
    "#### Resultados principales de la evaluación\n",
    "\n",
    "Accuracy promedio: 0.8307 (83.07%)\n",
    "Mejor desempeño en categorías mayoritarias (4 y 5)\n",
    "Desempeño más bajo en categorías minoritarias, lo cual es de esperarse en base a dataset que se tiene."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d27632-8d52-4e1f-8296-57e1955913c2",
   "metadata": {},
   "source": [
    "# 5. Evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54e5559-979e-4e0c-9e08-d9e61012dae6",
   "metadata": {},
   "source": [
    "### 5.1 Evaluación del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46dccebc-0845-49e0-bd1a-b375d5edaed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print('model' in locals())\n",
    "print('vectorizer' in locals())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5365ca3-6a92-4586-a8ee-66ce3253f620",
   "metadata": {},
   "source": [
    "El modelo (model) y el vectorizador (vectorizer) estén cargados correctamente en el entorno de ejecución.\n",
    "Resultado: La evaluación muestra que ambos objetos están presentes y correctamente cargados en memoria (True para ambos), lo que indica que están listos para usarse en la clasificación de nuevos tickets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3480f617-176d-46e3-998d-f514a26da4a8",
   "metadata": {},
   "source": [
    "# 6 Implementación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b61ad7c-82a1-4dab-88ed-e69911c542de",
   "metadata": {},
   "source": [
    "### 6.1 Sistema de Clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eab3437-3ef7-4115-8abd-43bbebd7a37a",
   "metadata": {},
   "source": [
    "Guardar el modelo y el vectorizador: Utiliza pickle para serializar los objetos model y vectorizer, guardándolos en archivos.\n",
    "Clasificador de Tickets: Definir la clase TicketClassifier que cargará el modelo y vectorizador guardados, y proporcionará funcionalidades para preprocesar texto y clasificar nuevos tickets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "deda6657-4463-432d-8782-12f9d16fae7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Modelo y vectorizador guardados exitosamente\n",
      "✓ Modelo y vectorizador cargados exitosamente\n"
     ]
    }
   ],
   "source": [
    "# PARTE 1: Guardar el modelo y vectorizador entrenados\n",
    "\n",
    "# 1.1 Guardar el modelo entrenado y el vectorizador\n",
    "def save_model_and_vectorizer(model, vectorizer, model_path='ticket_classifier_model.pkl', \n",
    "                            vectorizer_path='ticket_vectorizer.pkl'):\n",
    "    \"\"\"\n",
    "    Guarda el modelo y vectorizador en archivos pickle\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(model_path, 'wb') as model_file:\n",
    "            pickle.dump(model, model_file)\n",
    "        \n",
    "        with open(vectorizer_path, 'wb') as vectorizer_file:\n",
    "            pickle.dump(vectorizer, vectorizer_file)\n",
    "        \n",
    "        print(\"✓ Modelo y vectorizador guardados exitosamente\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error al guardar archivos: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# PARTE 2: Sistema de clasificación de nuevos tickets\n",
    "class TicketClassifier:\n",
    "    def __init__(self, model_path='ticket_classifier_model.pkl', \n",
    "                 vectorizer_path='ticket_vectorizer.pkl'):\n",
    "        \"\"\"\n",
    "        Inicializa el clasificador cargando el modelo y vectorizador guardados\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with open(model_path, 'rb') as model_file:\n",
    "                self.model = pickle.load(model_file)\n",
    "            \n",
    "            with open(vectorizer_path, 'rb') as vectorizer_file:\n",
    "                self.vectorizer = pickle.load(vectorizer_file)\n",
    "            \n",
    "            self.stop_words = set(stopwords.words('english'))\n",
    "            print(\"✓ Modelo y vectorizador cargados exitosamente\")\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error al cargar el modelo o vectorizador: {str(e)}\")\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Preprocesa el texto del ticket usando la misma lógica del entrenamiento\n",
    "        \"\"\"\n",
    "        # Eliminar caracteres especiales y números\n",
    "        text = re.sub(r\"[^a-zA-Z]\", \" \", str(text))\n",
    "        # Convertir a minúsculas\n",
    "        text = text.lower()\n",
    "        # Tokenizar y eliminar stopwords\n",
    "        words = word_tokenize(text)\n",
    "        words = [word for word in words if word not in self.stop_words]\n",
    "        return \" \".join(words)\n",
    "    \n",
    "    def classify_ticket(self, title, body):\n",
    "        \"\"\"\n",
    "        Clasifica un nuevo ticket basado en su título y cuerpo\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Combinar título y cuerpo\n",
    "            full_text = f\"{title} {body}\"\n",
    "            \n",
    "            # Preprocesar el texto\n",
    "            processed_text = self.preprocess_text(full_text)\n",
    "            \n",
    "            # Vectorizar el texto\n",
    "            text_vectorized = self.vectorizer.transform([processed_text])\n",
    "            \n",
    "            # Realizar predicción\n",
    "            category_predicted = self.model.predict(text_vectorized)[0]\n",
    "            \n",
    "            # Obtener probabilidades\n",
    "            probabilities = self.model.predict_proba(text_vectorized)[0]\n",
    "            \n",
    "            # Obtener las 3 categorías más probables con sus probabilidades\n",
    "            top_3_indices = np.argsort(probabilities)[-3:][::-1]\n",
    "            top_3_categories = [self.model.classes_[i] for i in top_3_indices]\n",
    "            top_3_probabilities = [probabilities[i] for i in top_3_indices]\n",
    "            \n",
    "            return {\n",
    "                'predicted_category': category_predicted,\n",
    "                'confidence': probabilities[list(self.model.classes_).index(category_predicted)],\n",
    "                'top_3_predictions': [\n",
    "                    {'category': cat, 'probability': prob} \n",
    "                    for cat, prob in zip(top_3_categories, top_3_probabilities)\n",
    "                ]\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {'error': f\"Error al clasificar el ticket: {str(e)}\"}\n",
    "\n",
    "# EJEMPLO DE USO\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Primero guardamos el modelo y vectorizador actuales\n",
    "    save_success = save_model_and_vectorizer(model, vectorizer)\n",
    "    \n",
    "    if save_success:\n",
    "        # 2. Crear instancia del clasificador\n",
    "        classifier = TicketClassifier()\n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198202eb-8a7a-42eb-8567-1048be40dcb4",
   "metadata": {},
   "source": [
    "### 6.2 Pruebas del Sistema\n",
    "**Primera Prueba:**\n",
    "Clasificar un primer ticket en tiempo real utilizando el clasificador cargado, mostrando los resultados y las probabilidades de las categorías predichas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5958cfe6-d735-4aea-a651-56c8ea15d8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados de la clasificación:\n",
      "Categoría predicha: 5\n",
      "Nivel de confianza: 75.77%\n",
      "\n",
      "Top 3 predicciones:\n",
      "Categoría 5: 75.77%\n",
      "Categoría 3: 17.40%\n",
      "Categoría 4: 6.10%\n"
     ]
    }
   ],
   "source": [
    "# 3. Ejemplo de un nuevo ticket\n",
    "nuevo_ticket_titulo_1 = \"password change\"\n",
    "nuevo_ticket_cuerpo_1 = \"wants hi change which until forced by change via has procedure changed recently regards accept decline requests\"\n",
    "\n",
    "# 4. Clasificar el nuevo ticket\n",
    "resultado = classifier.classify_ticket(nuevo_ticket_titulo_2, nuevo_ticket_cuerpo_2)\n",
    "\n",
    "# 5. Mostrar resultados\n",
    "print(\"\\nResultados de la clasificación:\")\n",
    "print(f\"Categoría predicha: {resultado['predicted_category']}\")\n",
    "print(f\"Nivel de confianza: {resultado['confidence']:.2%}\")\n",
    "print(\"\\nTop 3 predicciones:\")\n",
    "for pred in resultado['top_3_predictions']:\n",
    "    print(f\"Categoría {pred['category']}: {pred['probability']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440ecde0-e69c-456d-ab31-c3e14b8e2e43",
   "metadata": {},
   "source": [
    "**Segunda Prueba:** Clasificar un segundo ticket en tiempo real utilizando el clasificador cargado, mostrando los resultados y las probabilidades de las categorías predichas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd07992b-2af6-4a7b-b566-8cc3acb04f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados de la clasificación (Ticket de Alta Confianza):\n",
      "Categoría predicha: 6\n",
      "Nivel de confianza: 84.07%\n",
      "\n",
      "Top 3 predicciones:\n",
      "Categoría 6: 84.07%\n",
      "Categoría 4: 9.77%\n",
      "Categoría 5: 3.84%\n"
     ]
    }
   ],
   "source": [
    "# Clasificación de un nuevo ticket\n",
    "nuevo_ticket_titulo_4 = \"System outage affecting all users\"\n",
    "nuevo_ticket_cuerpo_4 = \"Critical system outage detected. All users are unable to access the platform. Immediate resolution needed.\"\n",
    "\n",
    "# Clasificación y visualización de resultados\n",
    "resultado_nuevo_confianza_alta = classifier.classify_ticket(nuevo_ticket_titulo_4, nuevo_ticket_cuerpo_4)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"\\nResultados de la clasificación (Ticket de Alta Confianza):\")\n",
    "print(f\"Categoría predicha: {resultado_nuevo_confianza_alta['predicted_category']}\")\n",
    "print(f\"Nivel de confianza: {resultado_nuevo_confianza_alta['confidence']:.2%}\")\n",
    "print(\"\\nTop 3 predicciones:\")\n",
    "for pred in resultado_nuevo_confianza_alta['top_3_predictions']:\n",
    "    print(f\"Categoría {pred['category']}: {pred['probability']:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433598b0-2b25-499b-b9ec-f4c93d9abdf1",
   "metadata": {},
   "source": [
    "El clasificador predijo la categoría 5 con una alta confianza del 84.07%. \n",
    "Este ticket, debido a su contenido más crítico y específico, debería generar una predicción con un nivel de confianza más alto, que es lo esperado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1255ce9-9171-47bc-83b5-7cd5922a3f57",
   "metadata": {},
   "source": [
    "### * Discusión de los Resultados obtenidos de las pruebas en tiempo real de nuevos tickets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfacb40-3469-4ea8-aa9d-a46a792e94ba",
   "metadata": {},
   "source": [
    "\n",
    "Este resultado nos lleva a los pasos proximos o recomendaciones para ir afinando y mejorando mucho más el modelo, lo que es parte del Machine Learning donde los modelos se pueden ir mejorando más y más."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce47727c-0495-4fed-abed-c5aff4b35439",
   "metadata": {},
   "source": [
    "Para discutir los niveles de confianza en la clasificación de tickets, podemos analizar el contenido, la complejidad del texto y la especificidad del caso. A continuación, se presentan posibles escenarios donde esperaríamos diferentes niveles de confianza:\n",
    "\n",
    "Confianza Baja\n",
    "Ejemplo de Caso:\n",
    "\n",
    "Títulos y cuerpos del ticket genéricos o ambiguos, sin contexto claro.\n",
    "Ejemplo:\n",
    "**Título:** \"Help needed\"\n",
    "**Cuerpo:** \"I'm having an issue. Please assist.\"\n",
    "**Razón:**\n",
    "El texto no proporciona información suficiente para identificar claramente la categoría, lo que lleva al modelo a distribuir las probabilidades entre varias categorías.\n",
    "\n",
    "Confianza Media\n",
    "Ejemplo de Caso:\n",
    "\n",
    "Tickets que combinan cierta especificidad pero con términos amplios o reutilizados.\n",
    "Ejemplo:\n",
    "**Título:** \"Login problem on dashboard\"\n",
    "**Cuerpo:** \"Getting error code 500 while logging in. Not sure what to do.\"\n",
    "**Razón:**\n",
    "Aunque se menciona un problema específico, como el código de error, el ticket sigue siendo lo suficientemente amplio como para estar asociado a múltiples categorías posibles.\n",
    "\n",
    "Confianza Alta\n",
    "Ejemplo de Caso:\n",
    "\n",
    "Tickets con información altamente específica o que incluyen palabras clave claras relacionadas con una categoría.\n",
    "Ejemplo:\n",
    "**Título:** \"Database connection timeout error\"\n",
    "**Cuerpo:** \"Our PostgreSQL server is returning a connection timeout error on port 5432. This is impacting real-time analytics.\"\n",
    "**Razón:**\n",
    "El uso de términos técnicos y la descripción detallada del problema permiten al modelo identificar claramente la categoría con alta confianza.\n",
    "\n",
    "Confianza Primaria (Top Categoría con Alto %)\n",
    "Definición:\n",
    "Se da cuando el modelo no solo predice una categoría principal con alta confianza, sino que la probabilidad de las categorías secundarias es significativamente más baja.\n",
    "\n",
    "Ejemplo de Caso:\n",
    "\n",
    "Título y cuerpo con un enfoque directo en una categoría específica.\n",
    "Ejemplo:\n",
    "**Título:** \"Critical server downtime notification\"\n",
    "**Cuerpo:** \"Server is completely down. Affects all users. Restart attempts failed.\"\n",
    "**Razón:**\n",
    "La estructura del ticket deja pocas dudas sobre la clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80af652e-0491-4683-99e5-e16b457d9cb9",
   "metadata": {},
   "source": [
    "\n",
    "**Pruebas de Validación**:\n",
    "   - Sistema responde correctamente a nuevos tickets\n",
    "   - Predicciones coherentes con el contexto\n",
    "   - Niveles de confianza apropiados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f84285a-3a3c-406b-9348-7358ddebf2e2",
   "metadata": {},
   "source": [
    "Muchas Gracias!!! :D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adba9271-b3b6-4213-9305-d5778fee94b4",
   "metadata": {},
   "source": [
    "**End!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701d5297-4103-497b-bde3-63a579cb2f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
